{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvBMur44LqoX"
      },
      "source": [
        "# Klasyfikacja obrazów metodą Vision Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvkwqJ5bLqoc"
      },
      "source": [
        "## Wstęp\n",
        "Opracowane na podstawie:\n",
        "*  [Vision Transformer (ViT) model, Alexey Dosovitskiy i inni ](https://arxiv.org/abs/2010.11929)\n",
        "*  [Image classification with Vision Transformer, Khalid Salama](https://keras.io/examples/vision/image_classification_with_vision_transformer/)\n",
        "\n",
        "* [Vision Transformers for Brain Tumor classification, \n",
        "RAAGULBHARATWAJ K ](https://www.kaggle.com/code/raagulbharatwajk/vision-transformers-for-brain-tumor-classification)\n",
        "\n",
        "Model ViT korzysta z architektury Transformer z funkcją self-attention, bez użycia warstw konwolucyjnych.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU60nq0aLqod"
      },
      "source": [
        "## Instalacja i import bibliotek"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROBgC9PiP2nL",
        "outputId": "135cff82-e19f-4e1c-d003-16185cf4cc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rozdział datset na test, train, val\n",
        "import splitfolders\n",
        "splitfolders.ratio(\"/content/gdrive/MyDrive/Colab Notebooks/Spl_data_jpg/\", \n",
        "                   output=\"/content/gdrive/MyDrive/Colab Notebooks/Spp_data/\", \n",
        "                   seed=42, \n",
        "                   ratio=(.8,0.0,.2), \n",
        "                   group_prefix=None, \n",
        "                   move=False "
      ],
      "metadata": {
        "id": "JTfHNkdVuOXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# przepisanie zdjęć do folderów\n",
        "t_dir = \"/content/gdrive/MyDrive/Colab Notebooks/Data/HSIL\"\n",
        "trainPaths = sorted(list(paths.list_images(t_dir)))\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = 256, 256\n",
        "x_train = []\n",
        "y_train = []\n",
        "image_size = 256\n",
        "a = 0\n",
        "\n",
        "for imagePath in trainPaths:\n",
        "    image = cv2.imread(imagePath)\n",
        "    image = cv2.resize(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
        "    cv2.imwrite(\"/content/gdrive/MyDrive/Colab Notebooks/Spl_data_jpg/NSIL/s%d.jpg\" % a, image)\n",
        "    a+=1 "
      ],
      "metadata": {
        "id": "tbKkVFNFuO3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVzn7PYZL4Bj",
        "outputId": "f31dd27c-1d21-4c49-c065-459ff24950ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.20.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qV_Jr7jSLqod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ed7639d-1bbc-4914-8f7b-1407eb6eb4ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.model_selection as sk\n",
        "import math\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imutils import paths\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.metrics import Precision, Recall, SparseCategoricalAccuracy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from keras.utils import plot_model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wxc78pZLqof"
      },
      "source": [
        "## Przygotowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/gdrive/MyDrive/Colab Notebooks/Data/\"\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgFfhbhAMvdo",
        "outputId": "914b32b8-114e-4445-c2cd-67f7947e2534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {'HSIL':0,'LSIL':1,'NSIL':2}\n",
        "train_dir = \"/content/gdrive/MyDrive/Colab Notebooks/Spp_data/train\"\n",
        "test_dir = \"/content/gdrive/MyDrive/Colab Notebooks/Spp_data/test\"\n",
        "trainPaths = sorted(list(paths.list_images(train_dir)))\n",
        "testPaths = sorted(list(paths.list_images(test_dir)))\n",
        "random.seed(2)\n",
        "random.shuffle(trainPaths)\n",
        "random.shuffle(testPaths)\n",
        "print(f\"Train Data: {len(trainPaths)}\")\n",
        "print(f\"Test Data: {len(testPaths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGesrJ4V7OG7",
        "outputId": "3732972d-12dd-4f9c-d526-cc2f2ece3ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data: 733\n",
            "Test Data: 185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "image_size = 256\n",
        "for i in labels:\n",
        "    folderPath = os.path.join(train_dir,i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size, image_size))\n",
        "        x_train.append(img)\n",
        "        y_train.append(labels[i])\n",
        "        \n",
        "for i in labels:\n",
        "    folderPath = os.path.join(test_dir,i)\n",
        "    for j in tqdm(os.listdir(folderPath)):\n",
        "        img = cv2.imread(os.path.join(folderPath,j))\n",
        "        img = cv2.resize(img,(image_size,image_size))\n",
        "        x_train.append(img)\n",
        "        y_train.append(labels[i])\n",
        "        \n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azY5ZonVq2Pm",
        "outputId": "c4e5ef07-ef62-444b-f17a-f09bdd2c256f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 193/193 [00:00<00:00, 313.98it/s]\n",
            "100%|██████████| 168/168 [00:00<00:00, 319.36it/s]\n",
            "100%|██████████| 372/372 [00:01<00:00, 313.66it/s]\n",
            "100%|██████████| 49/49 [00:00<00:00, 382.35it/s]\n",
            "100%|██████████| 42/42 [00:00<00:00, 368.54it/s]\n",
            "100%|██████████| 94/94 [00:00<00:00, 353.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = shuffle(x_train,y_train, random_state=101)"
      ],
      "metadata": {
        "id": "gzMhWgEt9D3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x_train,y_train, test_size=0.2,random_state=101)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.125, random_state=101) # 0.125 x 0.8 = 0.2"
      ],
      "metadata": {
        "id": "VO42XZxl9G3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNwprlZiLqof",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e9a9c58-93b2-45c9-85e1-34dc00e429b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (734, 256, 256, 3) - y_train shape: (734,)\n",
            "x_test shape: (184, 256, 256, 3) - y_test shape: (184,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "print(f\"x_test shape: {x_val.shape} - y_test shape: {y_val.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXXBMXmbLqog"
      },
      "source": [
        "## Konfiguracja parametrów"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "num_classes = 3\n",
        "input_shape = (256, 256, 3)\n",
        "buffer_size = 512\n",
        "batch_size = 256\n",
        "image_size = 72 # rozmiar zdjęć używanych w augmentacji\n",
        "patch_size = 6 # rozmiar pól wyodrębnianych z obrazu\n",
        "num_patches = (image_size // patch_size) ** 2\n",
        "learning_rate = 0.001\n",
        "weight_decay = 0.0001\n",
        "layer_norm_eps = 1e-6\n",
        "transformer_layers = 8\n",
        "projection_dim = 64\n",
        "num_heads = 4\n",
        "transformer_units = [\n",
        "    projection_dim * 2,\n",
        "    projection_dim,\n",
        "] \n",
        "transformer_layers = 8\n",
        "mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "id": "7BYQjn4A-fv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b49QLdlLqoh"
      },
      "source": [
        "## Augmentacja danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sDkjoYcLqoi"
      },
      "outputs": [],
      "source": [
        "train_data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(factor=0.02),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"train_data_augmentation\",\n",
        ")\n",
        "\n",
        "test_data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "    ],\n",
        "    name=\"test_data_augmentation\",\n",
        ")\n",
        "\n",
        "train_data_augmentation.layers[0].adapt(x_train)\n",
        "test_data_augmentation.layers[0].adapt(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_fn_train(image, label):\n",
        "    return (train_data_augmentation(image), label)\n",
        "\n",
        "def map_fn_test(image, label):\n",
        "    return (test_data_augmentation(image), label)"
      ],
      "metadata": {
        "id": "GU_MI88v-K5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTO = tf.data.AUTOTUNE\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds_iterator = train_ds.as_numpy_iterator()\n",
        "batch = train_ds_iterator.next()\n",
        "train_ds = train_ds.shuffle(buffer_size).batch(batch_size).map(map_fn_train).prefetch(AUTO)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds = test_ds.batch(batch_size).map(map_fn_test).prefetch(AUTO)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_ds = val_ds.batch(batch_size).map(map_fn_test).prefetch(AUTO)"
      ],
      "metadata": {
        "id": "87x_PP2l-O3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLeMhGSTLqoj"
      },
      "source": [
        "## Perceptron wielowarstwowy (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "PU71B2xg-n9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0O0FfjELqok"
      },
      "source": [
        "## Utworzenie pól (patches) jako warstwy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShiftedPatchTokenization(layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        image_size=image_size,\n",
        "        patch_size=patch_size,\n",
        "        num_patches=num_patches,\n",
        "        projection_dim=projection_dim,\n",
        "        vanilla=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.vanilla = vanilla \n",
        "        self.image_size = image_size\n",
        "        self.patch_size = patch_size\n",
        "        self.half_patch = patch_size // 2\n",
        "        self.flatten_patches = layers.Reshape((num_patches, -1))\n",
        "        self.projection = layers.Dense(units=projection_dim)\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=layer_norm_eps)\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"vanilla\": self.vanilla,\n",
        "            \"image_size\": self.image_size,\n",
        "            \"patch_size\": self.patch_size,\n",
        "            \"half_patch\": self.half_patch\n",
        "        })\n",
        "        return config\n",
        "    \n",
        "    def crop_shift_pad(self, images, mode):\n",
        "        if mode == \"left-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = 0\n",
        "            shift_width = 0\n",
        "        elif mode == \"left-down\":\n",
        "            crop_height = 0\n",
        "            crop_width = self.half_patch\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = 0\n",
        "        elif mode == \"right-up\":\n",
        "            crop_height = self.half_patch\n",
        "            crop_width = 0\n",
        "            shift_height = 0\n",
        "            shift_width = self.half_patch\n",
        "        else:\n",
        "            crop_height = 0\n",
        "            crop_width = 0\n",
        "            shift_height = self.half_patch\n",
        "            shift_width = self.half_patch\n",
        "        \n",
        "        crop = tf.image.crop_to_bounding_box(\n",
        "            images,\n",
        "            offset_height=crop_height,\n",
        "            offset_width=crop_width,\n",
        "            target_height=self.image_size-self.half_patch,\n",
        "            target_width=self.image_size-self.half_patch,\n",
        "        )\n",
        "        shift_pad = tf.image.pad_to_bounding_box(\n",
        "            crop,\n",
        "            offset_height=shift_height,\n",
        "            offset_width=shift_width,\n",
        "            target_height=self.image_size,\n",
        "            target_width=self.image_size,\n",
        "        )\n",
        "        return shift_pad\n",
        "\n",
        "    def call(self, images):\n",
        "        if not self.vanilla:\n",
        "            images = tf.concat(\n",
        "                [\n",
        "                    images,\n",
        "                    self.crop_shift_pad(images, mode=\"left-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"left-down\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-up\"),\n",
        "                    self.crop_shift_pad(images, mode=\"right-down\"),\n",
        "                ],\n",
        "                axis=-1\n",
        "            )\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        flat_patches = self.flatten_patches(patches)\n",
        "        if not self.vanilla:\n",
        "            tokens = self.layer_norm(flat_patches)\n",
        "            tokens = self.projection(tokens)\n",
        "        else:\n",
        "            tokens = self.projection(flat_patches)\n",
        "        return (tokens, patches)"
      ],
      "metadata": {
        "id": "3dIYSfbN-aN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t22dZAIRLqol"
      },
      "source": [
        "Utworzone pola na przykładowym obrazie"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "id": "N9lOLOwbDQZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BrXE2o6Lqom",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "outputId": "ab8c04f7-3d1d-4dc4-e888-115ee1e07e06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
        "plt.imshow(image.astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
        ")\n",
        "patches = Patches(patch_size)(resized_image)\n",
        "print(f\"Image size: {image_size} X {image_size}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
        "\n",
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQzWiW9lLqom"
      },
      "source": [
        "## Warstwa \"kodowania\" pól (patches)\n",
        "\n",
        "Warstwa `PatchEncoder` liniowo przekształca pole (patch) poprzez rzutowanie na\n",
        "wektor o rozmiarze `projection_dim`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    def __init__(self, num_patches=num_patches, projection_dim=projection_dim):\n",
        "        super().__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"num_patches\": self.num_patches,\n",
        "            \"positions\": self.positions.numpy(),\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, encoded_patches):\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_patches = encoded_patches + encoded_positions\n",
        "        return encoded_patches"
      ],
      "metadata": {
        "id": "8yJg_Z3p-j3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionLSA(tf.keras.layers.MultiHeadAttention):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.tau = tf.Variable(\n",
        "            math.sqrt(float(self._key_dim)),\n",
        "            trainable=True\n",
        "        )\n",
        "        diag_attn_mask = 1 - tf.eye(num_patches)\n",
        "        self.diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n",
        "    \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"tau\": self.tau.numpy(),\n",
        "            \"diag_attn_mask\": self.diag_attn_mask.numpy(),\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def _compute_attention(\n",
        "        self,\n",
        "        query,\n",
        "        key,\n",
        "        value,\n",
        "        attention_mask=None,\n",
        "        training=None\n",
        "    ):\n",
        "        query = tf.multiply(query, 1.0 / self.tau)\n",
        "        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n",
        "        attention_scores = self._masked_softmax(attention_scores, attention_mask=self.diag_attn_mask)\n",
        "        attention_scores_dropout = self._dropout_layer(attention_scores, training=training)\n",
        "        attention_output = tf.einsum(self._combine_equation, attention_scores_dropout, value)\n",
        "        return attention_output, attention_scores"
      ],
      "metadata": {
        "id": "WoA_KfiP-klZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3XDWVxqLqon"
      },
      "source": [
        "## Model ViT\n",
        "\n",
        "Model ViT składa się z wielu bloków Transformer,\n",
        "które wykorzystują warstwę `layers.MultiHeadAttention` jako mechanizm self-attention zastosowany do sekwencji pól (patches). Bloki Transformer wytwarzają\n",
        "`[batch_size, num_patches, projection_dim]` tensor, który jest przetwarzany przez algorytm głowicy klasyfikatora z softmax w celu uzyskania ostatecznego wyniku prawdopodobieństwa klasy.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_classifier(vanilla=False):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3), name=\"input_layer\")\n",
        "    (tokens, _)  = ShiftedPatchTokenization(vanilla=vanilla)(inputs)\n",
        "    encoded_patches = PatchEncoder()(tokens)\n",
        "\n",
        "    for _ in range(transformer_layers):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        if not vanilla:\n",
        "            attention_output = MultiHeadAttentionLSA(\n",
        "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "            )(x1, x1)\n",
        "        else:\n",
        "            attention_output = layers.MultiHeadAttention(\n",
        "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
        "            )(x1, x1)\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
        "    logits = layers.Dense(num_classes, name=\"output_dense\", activation = 'softmax')(features)\n",
        "    model = keras.Model(inputs=inputs, outputs=logits)\n",
        "    return model"
      ],
      "metadata": {
        "id": "VFI0a9VO-qUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(\n",
        "        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n",
        "    ):\n",
        "        super(WarmUpCosine, self).__init__()\n",
        "\n",
        "        self.learning_rate_base = learning_rate_base\n",
        "        self.total_steps = total_steps\n",
        "        self.warmup_learning_rate = warmup_learning_rate\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.pi = tf.constant(np.pi)\n",
        "\n",
        "    def __call__(self, step):\n",
        "        if self.total_steps < self.warmup_steps:\n",
        "            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n",
        "\n",
        "        cos_annealed_lr = tf.cos(\n",
        "            self.pi\n",
        "            * (tf.cast(step, tf.float32) - self.warmup_steps)\n",
        "            / float(self.total_steps - self.warmup_steps)\n",
        "        )\n",
        "        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n",
        "\n",
        "        if self.warmup_steps > 0:\n",
        "            if self.learning_rate_base < self.warmup_learning_rate:\n",
        "                raise ValueError(\n",
        "                    \"Learning_rate_base must be larger or equal to \"\n",
        "                    \"warmup_learning_rate.\"\n",
        "                )\n",
        "            slope = (\n",
        "                self.learning_rate_base - self.warmup_learning_rate\n",
        "            ) / self.warmup_steps\n",
        "            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n",
        "            learning_rate = tf.where(\n",
        "                step < self.warmup_steps, warmup_rate, learning_rate\n",
        "            )\n",
        "        return tf.where(\n",
        "            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n",
        "        )"
      ],
      "metadata": {
        "id": "DDlANeJO-suH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys1_FqbpLqon"
      },
      "source": [
        "## Komplicja, trenowanie i testowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir='logs'\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "-vReB0nGK216"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model):\n",
        "    total_steps = int((len(x_train) / batch_size) * num_epochs)\n",
        "    warmup_epoch_percentage = 0.10\n",
        "    warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
        "    scheduled_lrs = WarmUpCosine(\n",
        "        learning_rate_base=learning_rate,\n",
        "        total_steps=total_steps,\n",
        "        warmup_learning_rate=0.0,\n",
        "        warmup_steps=warmup_steps,\n",
        "    )\n",
        "    \n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_ds,\n",
        "        callbacks=[tensorboard_callback]\n",
        "    )\n",
        "    _, accuracy = model.evaluate(test_ds)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "Gx9G0esM-vyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(model):\n",
        "  pre = Precision()\n",
        "  re = Recall()\n",
        "  acc = SparseCategoricalAccuracy()\n",
        "  pred = []\n",
        "  for batch in test_ds.as_numpy_iterator(): \n",
        "    X, y = batch\n",
        "    yhat = np.argmax(model.predict(X), axis=1)\n",
        "    pred.append(yhat)\n",
        "    xy=model.predict(X)\n",
        "    pre.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, xy)\n",
        "\n",
        "  pred = np.array(pred)\n",
        "  pred = pred.reshape((pred.size,))\n",
        "  print(accuracy_score(y_test, pred))\n",
        "  ConfusionMatrixDisplay.from_predictions(y_test, pred)\n",
        "  tf.keras.utils.plot_model(model,show_shapes=True)\n",
        "  print(classification_report(y_test, pred, target_names=labels))\n"
      ],
      "metadata": {
        "id": "vM9ZPPP-w1vW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.keras.utils.plot_model(vit_sl,show_shapes=True)"
      ],
      "metadata": {
        "id": "_DaqXlNsZULX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing(vit_sl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "5hh7Qf92QlOL",
        "outputId": "3bc54159-06a6-46c4-dbfa-0d3bc5ed7317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 7s 880ms/step\n",
            "6/6 [==============================] - 3s 521ms/step\n",
            "tf.Tensor(0.7118644, shape=(), dtype=float32) tf.Tensor(0.9692308, shape=(), dtype=float32) tf.Tensor(0.4728261, shape=(), dtype=float32)\n",
            "0.47282608695652173\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        HSIL       0.43      0.06      0.10        54\n",
            "        LSIL       0.48      0.21      0.29        47\n",
            "        NSIL       0.47      0.89      0.62        83\n",
            "\n",
            "    accuracy                           0.47       184\n",
            "   macro avg       0.46      0.39      0.34       184\n",
            "weighted avg       0.46      0.47      0.38       184\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/gdrive/MyDrive/Colab Notebooks/Data/NSIL/pow. 40/1b.bmp\"\n",
        "image = tf.keras.preprocessing.image.load_img(image_path, target_size=(72, 72))\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "image =  np.expand_dims(image, 0)\n",
        "yp = vit_sl.predict(image)\n",
        "print(yp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpx8zpH2ioaJ",
        "outputId": "688545eb-4a2e-4f09-ab5d-53200ac84039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step\n",
            "[[0.20321299 0.2593461  0.53744096]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_sl = create_vit_classifier(vanilla=False)\n",
        "history = run_experiment(vit_sl)\n",
        "testing(vit_sl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8KGxU8VJ-0d8",
        "outputId": "73165ee5-8bcc-4180-cdd9-1e2d7e63a2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 16s 1s/step - loss: 9.9051 - accuracy: 0.4252 - val_loss: 3.2940 - val_accuracy: 0.2174\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 2s 646ms/step - loss: 5.3863 - accuracy: 0.3302 - val_loss: 2.6264 - val_accuracy: 0.5652\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 2s 669ms/step - loss: 2.9790 - accuracy: 0.4735 - val_loss: 2.1172 - val_accuracy: 0.3152\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 3s 883ms/step - loss: 1.9567 - accuracy: 0.4470 - val_loss: 1.0595 - val_accuracy: 0.4565\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 2s 639ms/step - loss: 1.6113 - accuracy: 0.4548 - val_loss: 0.9239 - val_accuracy: 0.5761\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 2s 702ms/step - loss: 1.2778 - accuracy: 0.4766 - val_loss: 1.2288 - val_accuracy: 0.3478\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 2s 671ms/step - loss: 1.2239 - accuracy: 0.4813 - val_loss: 0.9563 - val_accuracy: 0.5761\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 3s 891ms/step - loss: 1.1903 - accuracy: 0.4907 - val_loss: 0.9600 - val_accuracy: 0.5109\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 3s 713ms/step - loss: 0.9720 - accuracy: 0.5561 - val_loss: 0.8688 - val_accuracy: 0.6087\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 2s 708ms/step - loss: 1.0057 - accuracy: 0.5483 - val_loss: 0.8706 - val_accuracy: 0.6196\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 2s 669ms/step - loss: 0.9460 - accuracy: 0.5779 - val_loss: 0.9021 - val_accuracy: 0.5652\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 2s 654ms/step - loss: 0.9231 - accuracy: 0.5483 - val_loss: 0.8869 - val_accuracy: 0.5978\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 3s 867ms/step - loss: 0.9366 - accuracy: 0.5530 - val_loss: 0.8655 - val_accuracy: 0.6522\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 3s 695ms/step - loss: 0.8910 - accuracy: 0.5826 - val_loss: 0.8618 - val_accuracy: 0.6196\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 2s 708ms/step - loss: 0.8559 - accuracy: 0.6090 - val_loss: 0.8400 - val_accuracy: 0.6413\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 2s 704ms/step - loss: 0.8351 - accuracy: 0.6137 - val_loss: 0.7958 - val_accuracy: 0.6304\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 3s 876ms/step - loss: 0.7824 - accuracy: 0.6480 - val_loss: 0.8385 - val_accuracy: 0.6196\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 3s 763ms/step - loss: 0.7649 - accuracy: 0.6433 - val_loss: 0.9040 - val_accuracy: 0.5978\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 2s 703ms/step - loss: 0.7737 - accuracy: 0.6604 - val_loss: 0.7894 - val_accuracy: 0.6413\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 2s 707ms/step - loss: 0.7609 - accuracy: 0.6449 - val_loss: 0.8349 - val_accuracy: 0.5978\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 3s 800ms/step - loss: 0.7243 - accuracy: 0.6994 - val_loss: 0.7813 - val_accuracy: 0.6522\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 3s 811ms/step - loss: 0.6650 - accuracy: 0.6885 - val_loss: 0.7450 - val_accuracy: 0.6522\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 2s 645ms/step - loss: 0.6870 - accuracy: 0.6994 - val_loss: 0.7938 - val_accuracy: 0.6196\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 3s 718ms/step - loss: 0.7074 - accuracy: 0.6947 - val_loss: 0.7729 - val_accuracy: 0.6522\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 3s 827ms/step - loss: 0.6408 - accuracy: 0.7243 - val_loss: 0.8369 - val_accuracy: 0.6087\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 0.6744 - accuracy: 0.7181 - val_loss: 0.7924 - val_accuracy: 0.6304\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 2s 668ms/step - loss: 0.6259 - accuracy: 0.7352 - val_loss: 0.7752 - val_accuracy: 0.6304\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 2s 713ms/step - loss: 0.6267 - accuracy: 0.7321 - val_loss: 0.7688 - val_accuracy: 0.6848\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 2s 723ms/step - loss: 0.6082 - accuracy: 0.7430 - val_loss: 0.7650 - val_accuracy: 0.6739\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 3s 688ms/step - loss: 0.5805 - accuracy: 0.7679 - val_loss: 0.7327 - val_accuracy: 0.6957\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 3s 704ms/step - loss: 0.5810 - accuracy: 0.7368 - val_loss: 0.6948 - val_accuracy: 0.6848\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 3s 758ms/step - loss: 0.6054 - accuracy: 0.7227 - val_loss: 0.7315 - val_accuracy: 0.7065\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 2s 683ms/step - loss: 0.5623 - accuracy: 0.7539 - val_loss: 0.7273 - val_accuracy: 0.6848\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 2s 679ms/step - loss: 0.5321 - accuracy: 0.7648 - val_loss: 0.7466 - val_accuracy: 0.6848\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 2s 671ms/step - loss: 0.5057 - accuracy: 0.8022 - val_loss: 0.7034 - val_accuracy: 0.7283\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 3s 737ms/step - loss: 0.4967 - accuracy: 0.7975 - val_loss: 0.6895 - val_accuracy: 0.7391\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 2s 686ms/step - loss: 0.5072 - accuracy: 0.7928 - val_loss: 0.7746 - val_accuracy: 0.6848\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 0.4767 - accuracy: 0.8193 - val_loss: 0.7584 - val_accuracy: 0.6957\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.4778 - accuracy: 0.8084 - val_loss: 0.7092 - val_accuracy: 0.7391\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 2s 724ms/step - loss: 0.5267 - accuracy: 0.7866 - val_loss: 0.7635 - val_accuracy: 0.7283\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.4558 - accuracy: 0.8255 - val_loss: 0.7687 - val_accuracy: 0.6413\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 2s 706ms/step - loss: 0.4451 - accuracy: 0.8209 - val_loss: 0.6628 - val_accuracy: 0.6848\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 2s 706ms/step - loss: 0.4274 - accuracy: 0.8193 - val_loss: 0.6834 - val_accuracy: 0.7283\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 3s 731ms/step - loss: 0.4220 - accuracy: 0.8364 - val_loss: 0.7630 - val_accuracy: 0.7283\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 2s 682ms/step - loss: 0.4243 - accuracy: 0.8318 - val_loss: 0.7769 - val_accuracy: 0.6848\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 2s 660ms/step - loss: 0.4508 - accuracy: 0.8069 - val_loss: 0.7119 - val_accuracy: 0.7065\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 2s 663ms/step - loss: 0.4542 - accuracy: 0.8037 - val_loss: 0.6974 - val_accuracy: 0.7283\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 3s 745ms/step - loss: 0.4055 - accuracy: 0.8255 - val_loss: 0.8110 - val_accuracy: 0.6630\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 2s 649ms/step - loss: 0.3877 - accuracy: 0.8287 - val_loss: 0.7996 - val_accuracy: 0.6739\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.3776 - accuracy: 0.8645 - val_loss: 0.7936 - val_accuracy: 0.6848\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 2s 712ms/step - loss: 0.3637 - accuracy: 0.8505 - val_loss: 0.7329 - val_accuracy: 0.7065\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 3s 758ms/step - loss: 0.3065 - accuracy: 0.8972 - val_loss: 0.7197 - val_accuracy: 0.7391\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 2s 642ms/step - loss: 0.3703 - accuracy: 0.8505 - val_loss: 0.7933 - val_accuracy: 0.7391\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 2s 663ms/step - loss: 0.3121 - accuracy: 0.8723 - val_loss: 0.8980 - val_accuracy: 0.7174\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.3359 - accuracy: 0.8692 - val_loss: 0.8688 - val_accuracy: 0.6848\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 2s 717ms/step - loss: 0.3528 - accuracy: 0.8614 - val_loss: 1.0106 - val_accuracy: 0.6957\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 2s 689ms/step - loss: 0.3489 - accuracy: 0.8520 - val_loss: 0.9574 - val_accuracy: 0.6848\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.4146 - accuracy: 0.8318 - val_loss: 1.1247 - val_accuracy: 0.7283\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 2s 656ms/step - loss: 0.4596 - accuracy: 0.8380 - val_loss: 0.9066 - val_accuracy: 0.6522\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 2s 726ms/step - loss: 0.4427 - accuracy: 0.8411 - val_loss: 0.9361 - val_accuracy: 0.6848\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 2s 638ms/step - loss: 0.3403 - accuracy: 0.8801 - val_loss: 0.9198 - val_accuracy: 0.7065\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 2s 667ms/step - loss: 0.3467 - accuracy: 0.8785 - val_loss: 0.8261 - val_accuracy: 0.6630\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 2s 666ms/step - loss: 0.3181 - accuracy: 0.8785 - val_loss: 0.8572 - val_accuracy: 0.7283\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 2s 688ms/step - loss: 0.2967 - accuracy: 0.8754 - val_loss: 1.0141 - val_accuracy: 0.7065\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 3s 941ms/step - loss: 0.3440 - accuracy: 0.8692 - val_loss: 0.8527 - val_accuracy: 0.7065\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 2s 647ms/step - loss: 0.2937 - accuracy: 0.8816 - val_loss: 0.8640 - val_accuracy: 0.7500\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 2s 721ms/step - loss: 0.2448 - accuracy: 0.9050 - val_loss: 0.9513 - val_accuracy: 0.6957\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 2s 673ms/step - loss: 0.2694 - accuracy: 0.8879 - val_loss: 0.9546 - val_accuracy: 0.6957\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 3s 926ms/step - loss: 0.2839 - accuracy: 0.8879 - val_loss: 0.9748 - val_accuracy: 0.7283\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 2s 653ms/step - loss: 0.2760 - accuracy: 0.9019 - val_loss: 0.8754 - val_accuracy: 0.7826\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 3s 937ms/step - loss: 0.2290 - accuracy: 0.9143 - val_loss: 0.9061 - val_accuracy: 0.7609\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 3s 826ms/step - loss: 0.2808 - accuracy: 0.8738 - val_loss: 1.1141 - val_accuracy: 0.7283\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 2s 691ms/step - loss: 0.2271 - accuracy: 0.9143 - val_loss: 1.1781 - val_accuracy: 0.6848\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 2s 705ms/step - loss: 0.2510 - accuracy: 0.9237 - val_loss: 0.9840 - val_accuracy: 0.6957\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 2s 658ms/step - loss: 0.2383 - accuracy: 0.8988 - val_loss: 1.0629 - val_accuracy: 0.7283\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 3s 779ms/step - loss: 0.2709 - accuracy: 0.8972 - val_loss: 1.0668 - val_accuracy: 0.7391\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 2s 646ms/step - loss: 0.2643 - accuracy: 0.9097 - val_loss: 0.8885 - val_accuracy: 0.7500\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 2s 663ms/step - loss: 0.2235 - accuracy: 0.9237 - val_loss: 0.9886 - val_accuracy: 0.7826\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 2s 683ms/step - loss: 0.2387 - accuracy: 0.9081 - val_loss: 0.9573 - val_accuracy: 0.7500\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 3s 783ms/step - loss: 0.2742 - accuracy: 0.9159 - val_loss: 0.9990 - val_accuracy: 0.7283\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 3s 808ms/step - loss: 0.2192 - accuracy: 0.9128 - val_loss: 1.0914 - val_accuracy: 0.6739\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 2s 722ms/step - loss: 0.2175 - accuracy: 0.9190 - val_loss: 1.0070 - val_accuracy: 0.6957\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 2s 693ms/step - loss: 0.2079 - accuracy: 0.9315 - val_loss: 1.0011 - val_accuracy: 0.7174\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 2s 674ms/step - loss: 0.1922 - accuracy: 0.9268 - val_loss: 1.0582 - val_accuracy: 0.7609\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 2s 722ms/step - loss: 0.2037 - accuracy: 0.9330 - val_loss: 1.0087 - val_accuracy: 0.7609\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 3s 918ms/step - loss: 0.1962 - accuracy: 0.9252 - val_loss: 1.1033 - val_accuracy: 0.7826\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 3s 699ms/step - loss: 0.2091 - accuracy: 0.9190 - val_loss: 1.1762 - val_accuracy: 0.7609\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 2s 666ms/step - loss: 0.2013 - accuracy: 0.9330 - val_loss: 0.9955 - val_accuracy: 0.7717\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 2s 661ms/step - loss: 0.2173 - accuracy: 0.9174 - val_loss: 1.3092 - val_accuracy: 0.7717\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 3s 932ms/step - loss: 0.2357 - accuracy: 0.9174 - val_loss: 1.1450 - val_accuracy: 0.7391\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 2s 648ms/step - loss: 0.1796 - accuracy: 0.9315 - val_loss: 1.1687 - val_accuracy: 0.7717\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 2s 709ms/step - loss: 0.2050 - accuracy: 0.9206 - val_loss: 1.1830 - val_accuracy: 0.7935\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 2s 665ms/step - loss: 0.1929 - accuracy: 0.9268 - val_loss: 1.0702 - val_accuracy: 0.7174\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 3s 791ms/step - loss: 0.1990 - accuracy: 0.9237 - val_loss: 1.0426 - val_accuracy: 0.7391\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 2s 631ms/step - loss: 0.1779 - accuracy: 0.9268 - val_loss: 1.1846 - val_accuracy: 0.7500\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 2s 670ms/step - loss: 0.1410 - accuracy: 0.9502 - val_loss: 1.2252 - val_accuracy: 0.7391\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 3s 718ms/step - loss: 0.1817 - accuracy: 0.9283 - val_loss: 1.1440 - val_accuracy: 0.7717\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 3s 767ms/step - loss: 0.1617 - accuracy: 0.9455 - val_loss: 1.1186 - val_accuracy: 0.7717\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 2s 697ms/step - loss: 0.1357 - accuracy: 0.9579 - val_loss: 1.0991 - val_accuracy: 0.7717\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 2s 647ms/step - loss: 0.2072 - accuracy: 0.9252 - val_loss: 1.0924 - val_accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 446ms/step - loss: 0.7157 - accuracy: 0.7337\n",
            "Test accuracy: 73.37%\n",
            "6/6 [==============================] - 1s 32ms/step\n",
            "6/6 [==============================] - 0s 28ms/step\n",
            "0.7336956521739131\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        HSIL       0.66      0.78      0.71        54\n",
            "        LSIL       0.59      0.36      0.45        47\n",
            "        NSIL       0.84      0.92      0.87        83\n",
            "\n",
            "    accuracy                           0.73       184\n",
            "   macro avg       0.69      0.69      0.68       184\n",
            "weighted avg       0.72      0.73      0.72       184\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_sl.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk9y2vz-ZcmI",
        "outputId": "48b69d63-e49d-4bc2-944d-c63f144b6d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_layer (InputLayer)       [(None, 72, 72, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " shifted_patch_tokenization_6 (  ((None, 144, 64),   35704       ['input_layer[0][0]']            \n",
            " ShiftedPatchTokenization)       (None, 12, 12, 540                                               \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " patch_encoder_6 (PatchEncoder)  (None, 144, 64)     9216        ['shifted_patch_tokenization_6[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " layer_normalization_109 (Layer  (None, 144, 64)     128         ['patch_encoder_6[0][0]']        \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_48 (M  (None, 144, 64)     66369       ['layer_normalization_109[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " add_96 (Add)                   (None, 144, 64)      0           ['multi_head_attention_lsa_48[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'patch_encoder_6[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_110 (Layer  (None, 144, 64)     128         ['add_96[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_115 (Dense)              (None, 144, 128)     8320        ['layer_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " dropout_114 (Dropout)          (None, 144, 128)     0           ['dense_115[0][0]']              \n",
            "                                                                                                  \n",
            " dense_116 (Dense)              (None, 144, 64)      8256        ['dropout_114[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_115 (Dropout)          (None, 144, 64)      0           ['dense_116[0][0]']              \n",
            "                                                                                                  \n",
            " add_97 (Add)                   (None, 144, 64)      0           ['dropout_115[0][0]',            \n",
            "                                                                  'add_96[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_111 (Layer  (None, 144, 64)     128         ['add_97[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_49 (M  (None, 144, 64)     66369       ['layer_normalization_111[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " add_98 (Add)                   (None, 144, 64)      0           ['multi_head_attention_lsa_49[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_97[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_112 (Layer  (None, 144, 64)     128         ['add_98[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_117 (Dense)              (None, 144, 128)     8320        ['layer_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " dropout_116 (Dropout)          (None, 144, 128)     0           ['dense_117[0][0]']              \n",
            "                                                                                                  \n",
            " dense_118 (Dense)              (None, 144, 64)      8256        ['dropout_116[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_117 (Dropout)          (None, 144, 64)      0           ['dense_118[0][0]']              \n",
            "                                                                                                  \n",
            " add_99 (Add)                   (None, 144, 64)      0           ['dropout_117[0][0]',            \n",
            "                                                                  'add_98[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_113 (Layer  (None, 144, 64)     128         ['add_99[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_50 (M  (None, 144, 64)     66369       ['layer_normalization_113[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " add_100 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_50[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_99[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_114 (Layer  (None, 144, 64)     128         ['add_100[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_119 (Dense)              (None, 144, 128)     8320        ['layer_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " dropout_118 (Dropout)          (None, 144, 128)     0           ['dense_119[0][0]']              \n",
            "                                                                                                  \n",
            " dense_120 (Dense)              (None, 144, 64)      8256        ['dropout_118[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_119 (Dropout)          (None, 144, 64)      0           ['dense_120[0][0]']              \n",
            "                                                                                                  \n",
            " add_101 (Add)                  (None, 144, 64)      0           ['dropout_119[0][0]',            \n",
            "                                                                  'add_100[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_115 (Layer  (None, 144, 64)     128         ['add_101[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_51 (M  (None, 144, 64)     66369       ['layer_normalization_115[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " add_102 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_51[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_101[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_116 (Layer  (None, 144, 64)     128         ['add_102[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_121 (Dense)              (None, 144, 128)     8320        ['layer_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " dropout_120 (Dropout)          (None, 144, 128)     0           ['dense_121[0][0]']              \n",
            "                                                                                                  \n",
            " dense_122 (Dense)              (None, 144, 64)      8256        ['dropout_120[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_121 (Dropout)          (None, 144, 64)      0           ['dense_122[0][0]']              \n",
            "                                                                                                  \n",
            " add_103 (Add)                  (None, 144, 64)      0           ['dropout_121[0][0]',            \n",
            "                                                                  'add_102[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_117 (Layer  (None, 144, 64)     128         ['add_103[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_52 (M  (None, 144, 64)     66369       ['layer_normalization_117[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_117[0][0]']\n",
            "                                                                                                  \n",
            " add_104 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_52[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_103[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_118 (Layer  (None, 144, 64)     128         ['add_104[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_123 (Dense)              (None, 144, 128)     8320        ['layer_normalization_118[0][0]']\n",
            "                                                                                                  \n",
            " dropout_122 (Dropout)          (None, 144, 128)     0           ['dense_123[0][0]']              \n",
            "                                                                                                  \n",
            " dense_124 (Dense)              (None, 144, 64)      8256        ['dropout_122[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_123 (Dropout)          (None, 144, 64)      0           ['dense_124[0][0]']              \n",
            "                                                                                                  \n",
            " add_105 (Add)                  (None, 144, 64)      0           ['dropout_123[0][0]',            \n",
            "                                                                  'add_104[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_119 (Layer  (None, 144, 64)     128         ['add_105[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_53 (M  (None, 144, 64)     66369       ['layer_normalization_119[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_119[0][0]']\n",
            "                                                                                                  \n",
            " add_106 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_53[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_105[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_120 (Layer  (None, 144, 64)     128         ['add_106[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_125 (Dense)              (None, 144, 128)     8320        ['layer_normalization_120[0][0]']\n",
            "                                                                                                  \n",
            " dropout_124 (Dropout)          (None, 144, 128)     0           ['dense_125[0][0]']              \n",
            "                                                                                                  \n",
            " dense_126 (Dense)              (None, 144, 64)      8256        ['dropout_124[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_125 (Dropout)          (None, 144, 64)      0           ['dense_126[0][0]']              \n",
            "                                                                                                  \n",
            " add_107 (Add)                  (None, 144, 64)      0           ['dropout_125[0][0]',            \n",
            "                                                                  'add_106[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_121 (Layer  (None, 144, 64)     128         ['add_107[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_54 (M  (None, 144, 64)     66369       ['layer_normalization_121[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_121[0][0]']\n",
            "                                                                                                  \n",
            " add_108 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_54[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_107[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_122 (Layer  (None, 144, 64)     128         ['add_108[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_127 (Dense)              (None, 144, 128)     8320        ['layer_normalization_122[0][0]']\n",
            "                                                                                                  \n",
            " dropout_126 (Dropout)          (None, 144, 128)     0           ['dense_127[0][0]']              \n",
            "                                                                                                  \n",
            " dense_128 (Dense)              (None, 144, 64)      8256        ['dropout_126[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_127 (Dropout)          (None, 144, 64)      0           ['dense_128[0][0]']              \n",
            "                                                                                                  \n",
            " add_109 (Add)                  (None, 144, 64)      0           ['dropout_127[0][0]',            \n",
            "                                                                  'add_108[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_123 (Layer  (None, 144, 64)     128         ['add_109[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " multi_head_attention_lsa_55 (M  (None, 144, 64)     66369       ['layer_normalization_123[0][0]',\n",
            " ultiHeadAttentionLSA)                                            'layer_normalization_123[0][0]']\n",
            "                                                                                                  \n",
            " add_110 (Add)                  (None, 144, 64)      0           ['multi_head_attention_lsa_55[0][\n",
            "                                                                 0]',                             \n",
            "                                                                  'add_109[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_124 (Layer  (None, 144, 64)     128         ['add_110[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " dense_129 (Dense)              (None, 144, 128)     8320        ['layer_normalization_124[0][0]']\n",
            "                                                                                                  \n",
            " dropout_128 (Dropout)          (None, 144, 128)     0           ['dense_129[0][0]']              \n",
            "                                                                                                  \n",
            " dense_130 (Dense)              (None, 144, 64)      8256        ['dropout_128[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_129 (Dropout)          (None, 144, 64)      0           ['dense_130[0][0]']              \n",
            "                                                                                                  \n",
            " add_111 (Add)                  (None, 144, 64)      0           ['dropout_129[0][0]',            \n",
            "                                                                  'add_110[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_125 (Layer  (None, 144, 64)     128         ['add_111[0][0]']                \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 9216)         0           ['layer_normalization_125[0][0]']\n",
            "                                                                                                  \n",
            " dropout_130 (Dropout)          (None, 9216)         0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " dense_131 (Dense)              (None, 2048)         18876416    ['dropout_130[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_131 (Dropout)          (None, 2048)         0           ['dense_131[0][0]']              \n",
            "                                                                                                  \n",
            " dense_132 (Dense)              (None, 1024)         2098176     ['dropout_131[0][0]']            \n",
            "                                                                                                  \n",
            " dropout_132 (Dropout)          (None, 1024)         0           ['dense_132[0][0]']              \n",
            "                                                                                                  \n",
            " output_dense (Dense)           (None, 3)            3075        ['dropout_132[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 21,688,323\n",
            "Trainable params: 21,688,323\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "environment": {
      "name": "tf2-gpu.2-4.m61",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m61"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}